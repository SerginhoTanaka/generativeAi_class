{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from time import sleep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"https://arxiv.org/pdf/2103.15348.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "data_dir = \"data\"\n",
    "loader = PyPDFDirectoryLoader(data_dir)\n",
    "docs = loader.load_and_split()\n",
    "\n",
    "# Create unique IDs for each document\n",
    "for doc in docs:\n",
    "    doc.metadata[\"id\"] = str(uuid.uuid4())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "data_dir = \"data\"\n",
    "loader = PyPDFDirectoryLoader(data_dir)\n",
    "docs = loader.load_and_split()\n",
    "\n",
    "# Create unique IDs for each document\n",
    "for doc in docs:\n",
    "    doc.metadata[\"id\"] = str(uuid.uuid4())\n",
    "\n",
    "# Initialize the embedding function\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key, model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "data_dir = \"data\"\n",
    "loader = PyPDFDirectoryLoader(data_dir)\n",
    "docs = loader.load()\n",
    "\n",
    "# Criar IDs únicos para cada documento\n",
    "for doc in docs:\n",
    "    doc.metadata[\"id\"] = str(uuid.uuid4())\n",
    "\n",
    "# Inicializar a função de embedding\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Inicializar embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key, model=\"text-embedding-ada-002\")\n",
    "pages = [doc.page_content for doc in docs]\n",
    "embedded_docs = embeddings.embed_documents(pages)\n",
    "\n",
    "embedding_dim = len(embedded_docs)\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "print(index.is_trained)\n",
    "docstore = InMemoryDocstore()\n",
    "index_to_docstore_id = {i: doc.metadata[\"id\"] for i, doc in enumerate(docs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 49\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# embedded_docs_array = np.array(embedded_docs, dtype=np.float32)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# index.add(embedded_docs_array)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m FAISS(\n\u001b[0;32m     44\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m     45\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m     46\u001b[0m     docstore\u001b[38;5;241m=\u001b[39mdocstore,\n\u001b[0;32m     47\u001b[0m     index_to_docstore_id\u001b[38;5;241m=\u001b[39mindex_to_docstore_id,\n\u001b[0;32m     48\u001b[0m )\n\u001b[1;32m---> 49\u001b[0m \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(vector_store\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39m_dict), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs in the collection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"You are an assistant for question-answering tasks. \u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    Use the following pieces of retrieved context to answer \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Sergio\\MyGit\\generativeAi_class\\env\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:491\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[1;34m(self, documents, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    490\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sergio\\MyGit\\generativeAi_class\\env\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:228\u001b[0m, in \u001b[0;36mFAISS.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    227\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_documents(texts)\n\u001b[1;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sergio\\MyGit\\generativeAi_class\\env\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:199\u001b[0m, in \u001b[0;36mFAISS.__add\u001b[1;34m(self, texts, embeddings, metadatas, ids)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_L2:\n\u001b[0;32m    198\u001b[0m     faiss\u001b[38;5;241m.\u001b[39mnormalize_L2(vector)\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Add information to docstore and index.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m ids \u001b[38;5;241m=\u001b[39m ids \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "File \u001b[1;32mc:\\Users\\Sergio\\MyGit\\generativeAi_class\\env\\Lib\\site-packages\\faiss\\class_wrappers.py:228\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_add\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Adds vectors to the index.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03mThe index must be trained before vectors can be added to it.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03mThe vectors are implicitly numbered in sequence. When `n` vectors are\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    `dtype` must be float32.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    227\u001b[0m n, d \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md\n\u001b[0;32m    229\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_c(n, swig_ptr(x))\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# embedded_docs_array = np.array(embedded_docs, dtype=np.float32)\n",
    "# index.add(embedded_docs_array)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id,\n",
    ")\n",
    "vector_store.add_documents(docs)\n",
    "\n",
    "\n",
    "print(\"There are\", len(vector_store.docstore._dict), \"docs in the collection\")\n",
    "\n",
    "system_prompt = (\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer \n",
    "    the question. If you don't know the answer, say that you \n",
    "    don't know. Use three sentences maximum and keep the \n",
    "    answer concise.\n",
    "    \\n\\n\n",
    "    {context}\n",
    "    \"\"\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "faiss_retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "rag_chain = RetrievalQA.from_llm(\n",
    "    llm=ChatOpenAI(openai_api_key=api_key),\n",
    "    retriever=faiss_retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "query = \"O que o PDF attention is all you need fala?\"\n",
    "result = rag_chain({\"query\": query})  # Corrected method call\n",
    "\n",
    "# Print the result\n",
    "print(result['result'])  # Access the answer from the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
